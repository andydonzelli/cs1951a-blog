{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "file_path = \"brooklyn_weather.csv\"\n",
    "with open(file_path, 'r', encoding='latin1') as file_reader:\n",
    "    reader = csv.reader(file_reader, delimiter=',', quotechar='\"')\n",
    "    for row in reader:\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bin_time', 'company', 'unix_time', 'sunny', 'windy', 'rainy', 'cloudy', 'temp', 'dew_point', 'uv_index', 'precip_intensity', 'wind_speed', 'cloud_cover', 'apparent_temperature'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "header = data[0]\n",
    "print(header, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values to floats (leave company as string)\n",
    "var_data = data[1:]\n",
    "clean_var_data = []\n",
    "for row in var_data:\n",
    "    r = []\n",
    "    for i in range(len(row)):\n",
    "        if i != 1:\n",
    "            r.append(float(row[i]))\n",
    "        else:\n",
    "            r.append(row[i])\n",
    "    clean_var_data.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 'Uber', 1406867400.0, 1.0, 0.0, 0.0, 0.0, 72.6, 65.06, 0.0, 0.0, 1.27, 0.37, 73.19]\n"
     ]
    }
   ],
   "source": [
    "print(clean_var_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to numpy array (w/o company)\n",
    "data_array = np.delete(np.array(clean_var_data), 1, 1).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print([header[0]] + header[2:], \"\\n\")\n",
    "print(data_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max of each variable\n",
    "maxs = data_array.max(axis=0)\n",
    "\n",
    "# Set irrelevant max variables to 1.0:\n",
    "# - bin_time : 0\n",
    "# - unix_time : 1\n",
    "maxs[:2] = 1.0\n",
    "print(maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize relevant variables\n",
    "normalized_data = np.divide(data_array, maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalized_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert company info back\n",
    "normalized_list = normalized_data.tolist()\n",
    "i = 0\n",
    "for row in normalized_list:\n",
    "    row.insert(1, clean_var_data[i][1])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(header, \"\\n\")\n",
    "print(normalized_list[2013045])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spit data based on company\n",
    "uber, lyft, citi, green_taxi, yellow_taxi = [], [], [], [], []\n",
    "\n",
    "for row in normalized_list:\n",
    "    if row[1] == 'Uber':\n",
    "        uber.append(row)\n",
    "    elif row[1] == 'Lyft':\n",
    "        lyft.append(row)\n",
    "    elif row[1] == 'citi':\n",
    "        citi.append(row)\n",
    "    elif row[1] == 'green_taxi':\n",
    "        green_taxi.append(row)\n",
    "    elif row[1] == 'yellow_taxi':\n",
    "        yellow_taxi.append(row)\n",
    "    else:\n",
    "        print(\"Company not found!\")\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(uber), len(lyft), len(citi), len(green_taxi), len(yellow_taxi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_list(list_of_lists):\n",
    "    list_copy = list(list_of_lists)\n",
    "    return [list(item) for item in set(tuple(row) for row in list_copy)]\n",
    "\n",
    "def bin_count(ride_data, index):\n",
    "    ride_copy = list(ride_data)\n",
    "    bin_times = [row[index] for row in ride_copy]\n",
    "    return Counter(bin_times)\n",
    "\n",
    "def sort_list(list_of_lists, index):\n",
    "    list_copy = list(list_of_lists)\n",
    "    return sorted(list_copy, key=itemgetter(index))\n",
    "     \n",
    "def append_bin_count(ride_service, bin_cnt):\n",
    "    ride_service_copy = list(ride_service)\n",
    "    for row in ride_service_copy:\n",
    "        bin_id = row[0]\n",
    "        row.append(bin_cnt[bin_id])\n",
    "    return ride_service_copy\n",
    "\n",
    "def append_time_of_day(ride_service):\n",
    "    ride_service_copy = list(ride_service)\n",
    "    for row in ride_service_copy:\n",
    "        row.append(row[0] % 24)\n",
    "    return ride_service_copy\n",
    "\n",
    "def get_weekday(ride_service):\n",
    "    ride_service_copy = list(ride_service)\n",
    "    for row in ride_service_copy:\n",
    "        row[2] = datetime.utcfromtimestamp(row[2]).weekday()\n",
    "    return ride_service_copy\n",
    "\n",
    "def append_pipeline(ride_service):\n",
    "    ride_service_copy = list(ride_service)\n",
    "    ride_service_bin_cnt = bin_count(ride_service_copy, 0)\n",
    "    ride_service_copy = get_weekday(ride_service)\n",
    "    ride_service_copy = set_list(ride_service_copy)\n",
    "    ride_service_copy = sort_list(ride_service_copy, 0)\n",
    "    ride_service_copy = append_bin_count(ride_service_copy, ride_service_bin_cnt)\n",
    "    ride_service_copy = append_time_of_day(ride_service_copy)\n",
    "    return ride_service_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append bin_count to each ride service\n",
    "uber = append_pipeline(uber)\n",
    "lyft = append_pipeline(lyft)\n",
    "citi = append_pipeline(citi)\n",
    "green_taxi = append_pipeline(green_taxi)\n",
    "yellow_taxi = append_pipeline(yellow_taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update header\n",
    "header.append('bin_cnt')\n",
    "header.append('time_of_day')\n",
    "header.remove('unix_time')\n",
    "header.insert(2, 'week_day')\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(uber), len(lyft), len(citi), len(green_taxi), len(yellow_taxi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(data, x_index, y_index):\n",
    "    x, y = [], []\n",
    "    for row in data:\n",
    "        x.append(row[x_index])\n",
    "        y.append(row[y_index])\n",
    "    return x, y\n",
    "\n",
    "def get_mean_per_hour(data, day_index):\n",
    "    # Week header : ['bin_time', 'bin_cnt', 'time_of_day']\n",
    "    data = data.copy()\n",
    "    day = {}\n",
    "    for row in data:\n",
    "        if row[2] == day_index:\n",
    "            time_of_day = row[len(row)-1]\n",
    "            bin_cnt = row[len(row)-2]\n",
    "            if time_of_day in day:\n",
    "                day[time_of_day].append(bin_cnt)\n",
    "            else:\n",
    "                day[time_of_day] = [bin_cnt]\n",
    "    x,y = [],[]\n",
    "    for key in sorted(day):\n",
    "        x.append(key)\n",
    "        y.append(np.mean(np.array(day[key])))\n",
    "    return x,y\n",
    "\n",
    "def plot_rides(x, y, title, file_name):\n",
    "    plt.xticks(x, np.arange(len(x)))\n",
    "#     plt.ylabel(\"Pickup Count\")\n",
    "#     plt.xlabel(\"Hour of day\")\n",
    "    plt.bar(x,y, color='#40C4FF')\n",
    "    plt.title(title)\n",
    "    plt.savefig(file_name, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mon - Sun : 0 - 6\n",
    "\n",
    "# Get averaged week day data \n",
    "x_mon, y_mon = get_mean_per_hour(citi, 0)\n",
    "x_tues, y_tues = get_mean_per_hour(citi, 1)\n",
    "x_wed, y_wed = get_mean_per_hour(citi, 2)\n",
    "x_thu, y_thu = get_mean_per_hour(citi, 3)\n",
    "x_fri, y_fri = get_mean_per_hour(citi, 4)\n",
    "x_sat, y_sat = get_mean_per_hour(citi, 5)\n",
    "x_sun, y_sun = get_mean_per_hour(citi, 6)\n",
    "\n",
    "# Plot each day\n",
    "plot_rides(x_mon, y_mon, \"Monday\", 'mon.png')\n",
    "plot_rides(x_tues, y_tues, \"Tuesday\", 'tue.png')\n",
    "plot_rides(x_wed, y_wed, \"Wednesday\", 'wed.png')\n",
    "plot_rides(x_thu, y_thu, \"Thursday\", 'thu.png')\n",
    "plot_rides(x_fri, y_fri, \"Friday\", 'fri.png')\n",
    "plot_rides(x_sat, y_sat, \"Saturday\", 'sat.png')\n",
    "plot_rides(x_sun, y_sun, \"Sunday\", 'sun.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def split_data(data, prob):\n",
    "    \"\"\"Split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    results = [], []\n",
    "    for row in data:\n",
    "        results[0 if random.random() < prob else 1].append(row)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x, y, test_pct):\n",
    "    \"\"\"Split the features X and the labels y into x_train, x_test and y_train, y_test\n",
    "    designated by test_pct. A common convention in data science is to do a 80% training\n",
    "    data 20% test data split\"\"\"\n",
    "    data = zip(x, y)                                # pair corresponding values\n",
    "    train, test = split_data(data, 1 - test_pct)    # split the data set of pairs\n",
    "    x_train, y_train = zip(*train)                  # magical un-zip trick\n",
    "    x_test, y_test = zip(*test)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultipleLinearRegression(X, y, linear_model):\n",
    "\n",
    "    lm = linear_model\n",
    "    ### DO NOT TOUCH THIS PORTION OF THE CODE###\n",
    "    params = np.append(lm.intercept_,lm.coef_)\n",
    "    predictions = lm.predict(X)\n",
    "\n",
    "    newX = np.append(np.ones((len(X),1)), X, axis=1)\n",
    "    MSE = (sum((y-predictions)**2))/(len(newX)-len(newX[0]))\n",
    "\n",
    "    var_b = MSE*(np.linalg.inv(np.dot(newX.T,newX)).diagonal())\n",
    "    sd_b = np.sqrt(np.abs(var_b))\n",
    "    ts_b = params/ sd_b\n",
    "\n",
    "    p_values =[2*(1-stats.t.cdf(np.abs(i),(len(newX)-1))) for i in ts_b]\n",
    "    myDF3 = pd.DataFrame()\n",
    "    myDF3[\"Coefficients\"],myDF3[\"Standard Errors\"],myDF3[\"t values\"],myDF3[\"Probabilites\"] = [params,sd_b,ts_b,p_values]\n",
    "    \n",
    "    print(myDF3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data, features, x_variables, y_variable):\n",
    "        X = []\n",
    "        y = []\n",
    "        for row in data:\n",
    "            if row == []:\n",
    "                continue\n",
    "            explanatory_var = []\n",
    "            ### TODO: Select independent variables that might best predict the dependent variables ###\n",
    "            for var in x_variables:\n",
    "                explanatory_var.append(float(row[features.index(var)]))\n",
    "            \n",
    "#             explanatory_var.append(\n",
    "#                 float(row[features.index('sunny')]))\n",
    "#             explanatory_var.append(\n",
    "#                 float(row[features.index('windy')]))\n",
    "#             explanatory_var.append(\n",
    "#                 float(row[features.index('rainy')]))\n",
    "#             explanatory_var.append(\n",
    "#                 float(row[features.index('cloudy')]))\n",
    "#             explanatory_var.append(\n",
    "#                 float(row[features.index('temp')]))\n",
    "#             explanatory_var.append(\n",
    "#                 float(row[features.index('dew_point')]))\n",
    "#             explanatory_var.append(\n",
    "#                 float(row[features.index('uv_index')]))\n",
    "#             explanatory_var.append(\n",
    "#                 float(row[features.index('precip_intensity')]))\n",
    "#             explanatory_var.append(\n",
    "#                 float(row[features.index('wind_speed')]))\n",
    "#             explanatory_var.append(\n",
    "#                 float(row[features.index('cloud_cover')]))\n",
    "#             explanatory_var.append(\n",
    "#                 float(row[features.index('apparent_temperature')]))\n",
    "            X.append(explanatory_var)\n",
    "            # Since our label bin_cnt is at the 2nd to the end of the row\n",
    "#             bin_cnt = int(row[len(row)-2])\n",
    "            y.append(int(row[features.index(y_variable)]))\n",
    "        return np.array(X, dtype='float64'), np.array(y, dtype='float64')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_regression(X, y, p):\n",
    "    ##################################################################################\n",
    "    # TODO: use train test split to split data into x_train, x_test, y_train, y_test #\n",
    "    ##################################################################################\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, p)\n",
    "    x_train = np.array(x_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    ###########################################################################\n",
    "    # TODO: Use Sci-Kit Learn to create the Linear Model and Output R-squared #\n",
    "    ###########################################################################\n",
    "\n",
    "    linear_model = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "    # Prints out the Report\n",
    "    MultipleLinearRegression(x_train, y_train, linear_model)\n",
    "\n",
    "    ##############################################################################\n",
    "    # TODO: print the training linear_model score, training mse, and testing mse #\n",
    "    ##############################################################################\n",
    "    y_train_pred = linear_model.predict(x_train)\n",
    "    y_test_pred = linear_model.predict(x_test)\n",
    "    print()\n",
    "    print(\"Training R-squared:\", r2_score(y_train, y_train_pred))\n",
    "    print(\"Training MSE:\", mean_squared_error(y_train, y_train_pred))\n",
    "    print(\"Testing MSE:\", mean_squared_error(y_test, y_test_pred))\n",
    "    print()\n",
    "    \n",
    "    return linear_model, x_test, y_test, y_test_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO not change this seed. It guarantees that all students perform the same train and test split\n",
    "# random.seed(1)\n",
    "# Setting p to 0.2 allows for a 80% training and 20% test split\n",
    "p = 0.2\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# ['bin_time', 'company', 'week_day', 'sunny', 'windy', 'rainy', 'cloudy', 'temp', 'dew_point', 'uv_index', 'precip_intensity', 'wind_speed', 'cloud_cover', 'apparent_temperature', 'bin_cnt', 'time_of_day']\n",
    "x_var = ['sunny', 'windy', 'rainy', 'cloudy', 'temp', 'dew_point', 'uv_index', 'precip_intensity', 'wind_speed', 'cloud_cover', 'apparent_temperature']        \n",
    "y_var = 'bin_cnt'\n",
    "\n",
    "# Prints variables used\n",
    "print(\"Variables\")\n",
    "print(\"=========\")\n",
    "for i in range(len(x_var)):\n",
    "    print(i, x_var[i])\n",
    "print(len(x_var), y_var)\n",
    "print()\n",
    "\n",
    "print(\"Uber\")\n",
    "print(\"====\")\n",
    "X_uber, y_uber = load_data(uber, header, x_var, y_var)\n",
    "_,_,_,_ = run_multi_regression(X_uber, y_uber, p)\n",
    "\n",
    "print(\"Lyft\")\n",
    "print(\"====\")\n",
    "X_lyft, y_lyft = load_data(lyft, header, x_var, y_var)\n",
    "_,_,_,_ = run_multi_regression(X_lyft, y_lyft, p)\n",
    "\n",
    "print(\"Citibike\")\n",
    "print(\"========\")\n",
    "X_citi, y_citi = load_data(citi, header, x_var, y_var)\n",
    "_,_,_,_ = run_multi_regression(X_citi, y_citi, p)\n",
    "\n",
    "print(\"Green Taxi\")\n",
    "print(\"==========\")\n",
    "X_green, y_green = load_data(green_taxi, header, x_var, y_var)\n",
    "_,_,_,_ = run_multi_regression(X_green, y_green, p)\n",
    "\n",
    "print(\"Yellow Taxi\")\n",
    "print(\"===========\")\n",
    "X_yellow, y_yellow = load_data(yellow_taxi, header, x_var, y_var)\n",
    "_,_,_,_ = run_multi_regression(X_yellow, y_yellow, p)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only one feature\n",
    "x_var = ['time_of_day']\n",
    "y_var = 'bin_cnt'\n",
    "\n",
    "print(\"Variables\")\n",
    "print(\"=========\")\n",
    "for i in range(len(x_var)):\n",
    "    print(i, x_var[i])\n",
    "print(len(x_var), y_var)\n",
    "print()\n",
    "\n",
    "print(\"Citibike\")\n",
    "print(\"========\")\n",
    "x_, y_ = load_data(citi, header, x_var, y_var)\n",
    "\n",
    "# Trim to have full day recordings\n",
    "x_ = x_[:-8]\n",
    "y_ = y_[:-8]\n",
    "\n",
    "# Reshape to group by day\n",
    "# x_ = np.reshape(x_, (-1,24))\n",
    "# y_ = np.reshape(y_, (-1,24))\n",
    "\n",
    "# Train: 40 days\n",
    "x_train = x_[:40*24]\n",
    "y_train = y_[:40*24]\n",
    "\n",
    "# Test: 20 days\n",
    "x_test = x_[:-20*24]\n",
    "y_test = y_[:-20*24]\n",
    "\n",
    "colors = ['#D500F9', '#2979FF', '#1DE9B6']\n",
    "lw = 2\n",
    "\n",
    "# Plot test points \n",
    "plt.scatter(x_test[:24], y_test[:24], color='#263238', s=30, marker='o', label=\"test points\")\n",
    "plt.plot(x_test[:24], y_test[:24], color='#37474F', linewidth=lw, \n",
    "         label='ground truth')\n",
    "\n",
    "for i, degree in enumerate([3, 5, 7]):\n",
    "    poly_model = make_pipeline(PolynomialFeatures(degree), Ridge())\n",
    "    poly_model.fit(x_train, y_train)\n",
    "    y_test_pred = poly_model.predict(x_test)\n",
    "    print(mean_squared_error(y_test, y_test_pred))\n",
    "    plt.plot(x_test[:24], y_test_pred[:24], color=colors[i], linewidth=lw,\n",
    "             label=\"degree %d\" % degree)\n",
    "\n",
    "plt.xlabel(\"Time of Day (hour)\")\n",
    "plt.ylabel(\"Number of Rides\")\n",
    "plt.title(\"Actual Ride Volume vs Predicted Ride Volume\")\n",
    "plt.xticks(x_test[:24], np.arange(len(x_test[:24])))\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(\"citi_poly_regression\", bbox_inches='tight')\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
